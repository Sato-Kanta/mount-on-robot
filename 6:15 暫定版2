#define STRICT
#define NOMINMAX
#include <opencv2/core/utility.hpp>
#include <opencv2/video/tracking.hpp>
#include <opencv2/videoio.hpp> // videoioのヘッダーをインクルード
#include <opencv2/highgui.hpp> // highguiのヘッダーをインクルード
#include <opencv2/imgproc.hpp>
#include <opencv2/imgcodecs.hpp>
#include <opencv2/imgproc/imgproc_c.h>
#include <opencv2/highgui/highgui_c.h>
#include<opencv2/objdetect/detection_based_tracker.hpp>
#include <iostream>
#include<string>
#include<vector>
#include<stdio.h>
#include<math.h>
#include "resource.h"
#include<process.h>
#include <windows.h>
#include <windowsx.h>
#include <tchar.h>
#include "cserial.h"
#include<opencv2/opencv.hpp>
#include <opencv2/core.hpp>
#include <opencv2/video.hpp>
#include<cstring>
#include <opencv2/imgcodecs.hpp>
#include <opencv2/tracking.hpp>
#include <numeric>      // std::iota
#include <algorithm>    // std::sort, std::stable_sort
#include <opencv2/video/background_segm.hpp>
#include <functional>

//CSerialインスタンスの宣言
CSerial* cserial;
//ダイアログ関数プロトタイプの宣言
BOOL CALLBACK DlgWndProc(HWND, UINT, WPARAM, LPARAM);
//WinAPI関連
HWND hWnd;
MSG msg;

//カメラ関連
unsigned int __stdcall camera(PVOID pv);
HANDLE threadHandle = NULL;
//--------------------------------------------
// Name:WinMain()
// Desc:アプリケーションのエントリー関数
//--------------------------------------------

static int operation_status = 5;
int STATUS = 0, state = 0; //モード変数
int Endflag = 0;
int send_count = 0;
int up_flag = 0, down_flag = 0, right_flag = 0, left_flag = 0, in_flag = 0, out_flag = 0, stop_flag = 0;
static int encoder_pitch_data = 0;
static int encoder_yaw_data = 0;
static int encoder_zoom_data = 0;

//pic-windows
enum eCODE {
	OFFSET, RESET,
	START, STOP,
	R_UP, R_DOWN,
	L_UP, L_DOWN,
	SPEED_UP, SPEED_DOWN,
	SEND_DATA, DATA_CHECK,
	NEUTRAL,
	REMOVE_SCOPE, UP, DOWN, LEFT, RIGHT, ZOOM_IN, ZOOM_OUT, BREAK,
	LEFTIN, LEFTOUT,RIGHTIN, RIGHTOUT,UPIN, UPOUT, DOWNIN, DOWNOUT
};

//--------------------------------------------
// Name:DlgWndProc()
// Desc:ダイアログ用ウィンドウプロシージャ
//--------------------------------------------
BOOL CALLBACK DlgWndProc(HWND hWnd, UINT iMsg, WPARAM wParam, LPARAM lParam)
{
	TCHAR szstr[256] = _T("");
	DWORD dwThread;
	static int roll_data, yaw_data, pitch_data;
	static short int s_flag = 0;// ss_flag = 0;
	static bool file_write = 0;		//ファイルに記録するかどうか
	static int file_flag = 0, write_flag = 0;
	SYSTEMTIME systime;//時間記録用

	char FileName[127] = { "FILE_AD" };//ファイルの名前用の文字列

	//変数の宣言
	//シリアル通信用
	int edit_data[28] = { 0 };	               //SEND_DATA用
	int check_data[2] = { 0,0 };			   //通信確認用

	//AD7150設定取得用
	unsigned static int ch2_data = 0, ch2_critical = 10000;	//ch2_data:筋収縮センサの値 ch2_critical:閾値
	unsigned static int ch1_data = 0, ch1_critical = 10000;	//ch1_data:加速度センサの値 ch1_critical:閾値
	static int VR = 0;//可変抵抗用

	static int speed_data = 0;//速度
	static int senser_threshold_per = 0;//閾値

	//グラフ表示関係
	static int g_scale = 1;  //data*g_scalse/12 表示調整
	//通信・ファイル出力操作用
	static int flags = 1;

	//カウンタ
	unsigned static int time_count = 0, Off_count = 0;

	//位置データ
	int i;

	static int neutral_count = 0;
	
	switch (iMsg)
	{
	case WM_INITDIALOG:
		//ダイアログボックスが生成されたとき
		Button_SetCheck(GetDlgItem(hWnd, IDC_BUTTON1), BST_CHECKED);
		cserial = new CSerial; 							// Cserialクラスを取得
		cserial->MakeBuffer(3, 28); 					// 送信用データを1byte、受信用データを4byte用意する。
		if (cserial->GetComNum(NULL) == 0) {
			MessageBox(hWnd, "接続を確認できません", "error", MB_OK);
			PostQuitMessage(0);
			//CSerialクラスの終了処理
			delete cserial;
			return 1;
		}
		//cserial->SetFindSerialPortName(0);
		cserial->SetSerialPortName("COM7");
		cserial->OpenSerialPort(); 					// シリアルポートをオープンする。
		cserial->SetSerialPort(57600, 1024, 1024);	// ボーレイトの設定
		cserial->SerialPortBufferClear(); 				// シリアルポートの送受信FIFOメモリをクリアする。
		return TRUE;
	case WM_COMMAND:

		SendMessage(GetDlgItem(hWnd, IDC_EDIT1), WM_SETFONT, (WPARAM)CreateFont(50, 0, 0, 0, FW_REGULAR, FALSE, FALSE, FALSE, DEFAULT_CHARSET, OUT_DEFAULT_PRECIS, CLIP_DEFAULT_PRECIS, PROOF_QUALITY, DEFAULT_PITCH, "ＭＳ Ｐゴシック"), MAKELPARAM(TRUE, 0));
		switch (LOWORD(wParam))
		{
		case IDC_BUTTON1:
			if (flags) {
				//SetWindowText(GetDlgItem(hWnd, IDC_EDIT1), _T("画面表示"));
				SetTimer(hWnd, 1, 1, NULL);//通信系
				SetTimer(hWnd, 2, 1, NULL);//表示系
				if (threadHandle != NULL) break;
				//スレッド起動
				threadHandle = (HANDLE)_beginthreadex(NULL, 0, camera, NULL, 0, (unsigned int*)&dwThread);
				flags = 0;

			}
			else {
				KillTimer(hWnd, 1);
				KillTimer(hWnd, 2);
				flags = 1;
			}
			break;
		case IDC_BUTTON2:
			SetWindowText(GetDlgItem(hWnd, IDC_EDIT1), _T("確認"));
			STATUS = 0;
			send_count = 2;
			break;
		
		case IDC_BUTTON8:
			STATUS = 1;
			send_count = 1;
			break;
		}
		return TRUE;
	case WM_TIMER:
		switch (LOWORD(wParam)) {
		case 1:

			/*========================receive data========================================================-*/
			cserial->m_senddata[0] = (unsigned char)SEND_DATA;				//確認用データを代入する。
			cserial->SerialPortBufferClear();
			cserial->SendSerialData(1);										//確認用データを送信する。
			cserial->ReceiveSerialData(28);//0815
			//とりあえず28byte分のデータを受け取る
			for (i = 0; i < 28; i++) {
				edit_data[i] = cserial->m_receivedata[i];
			}
			if ((edit_data[0] == DATA_CHECK) && (edit_data[27] == DATA_CHECK)) {//0と27番目のデータは確認用

				edit_data[2] <<= 8;				//1byte目と2バイト目は可変抵抗の値
				edit_data[1] |= edit_data[2];
				VR = edit_data[1] - 3000;

				edit_data[4] <<= 8;				//3バイト目と4byte目はhead_L（側頭筋収縮センサ）
				edit_data[3] |= edit_data[4];
				ch2_data = edit_data[3];

				edit_data[6] <<= 8;				//5,6byte目はロール角
				edit_data[5] |= edit_data[6];
				roll_data = edit_data[5];

				edit_data[8] <<= 8;				//7,8byteはヨー角
				edit_data[7] |= edit_data[8];
				yaw_data = edit_data[7];

				edit_data[10] <<= 8;
				edit_data[9] |= edit_data[10];	//9,10byte目はピッチ角
				pitch_data = edit_data[9];

				edit_data[12] <<= 8;			//L_critical(L閾値)
				edit_data[11] |= edit_data[12];
				ch2_critical = edit_data[11];

				edit_data[14] <<= 8;			//head_R (側頭筋収縮センサ)
				edit_data[13] |= edit_data[14];
				//xxx = edit_data[13];

				edit_data[16] <<= 8;			//speed_data
				edit_data[15] |= edit_data[16];
				speed_data = edit_data[15];

				edit_data[18] <<= 8;			//未使用
				edit_data[17] |= edit_data[18];
				senser_threshold_per = edit_data[17];

				edit_data[20] <<= 8;			//19,20byte目はピッチエンコーダの値
				edit_data[19] |= edit_data[20];
				encoder_pitch_data = edit_data[19];

				edit_data[22] <<= 8;			//21,22byte目はヨーエンコーダの値
				edit_data[21] |= edit_data[22];
				encoder_yaw_data = edit_data[21];

				edit_data[24] <<= 8;			//23,24byte目はズームエンコーダの値
				edit_data[23] |= edit_data[24];
				encoder_zoom_data = edit_data[23];

				edit_data[26] <<= 8;            //25,26byte目は運用状態
				edit_data[25] |= edit_data[26];
				operation_status = edit_data[25];
			}


			/*===================================seda data==================================================*/
			switch (send_count) {
			case 1:	//マスターにSTRATという値を送る
				cserial->m_senddata[0] = (unsigned char)START;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				operation_status = 0;
				send_count = 0;
				break;

			case 2://マスターにSTOPという値を送る
				cserial->m_senddata[0] = (unsigned char)STOP;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 19://マスターにNEUTRALという値を送る
				cserial->m_senddata[0] = (unsigned char)NEUTRAL;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 20://マスターにREMOVE_SCOPEという値を送る
				cserial->m_senddata[0] = (unsigned char)REMOVE_SCOPE;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 3:
				cserial->m_senddata[0] = (unsigned char)LEFT;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 4:
				cserial->m_senddata[0] = (unsigned char)RIGHT;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 5:
				cserial->m_senddata[0] = (unsigned char)UP;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 6:
				cserial->m_senddata[0] = (unsigned char)DOWN;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 7:
				cserial->m_senddata[0] = (unsigned char)ZOOM_IN;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 8:
				cserial->m_senddata[0] = (unsigned char)ZOOM_OUT;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 9:
				cserial->m_senddata[0] = (unsigned char)BREAK;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 10:
				cserial->m_senddata[0] = (unsigned char)LEFTIN;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 11:
				cserial->m_senddata[0] = (unsigned char)LEFTOUT;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 12:
				cserial->m_senddata[0] = (unsigned char)RIGHTIN;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 13:
				cserial->m_senddata[0] = (unsigned char)RIGHTOUT;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 14:
				cserial->m_senddata[0] = (unsigned char)UPIN;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 15:
				cserial->m_senddata[0] = (unsigned char)UPOUT;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 16:
				cserial->m_senddata[0] = (unsigned char)DOWNIN;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			case 17:
				cserial->m_senddata[0] = (unsigned char)DOWNOUT;
				cserial->SerialPortBufferClear();
				cserial->SendSerialData(1);
				send_count = 0;
				break;

			}
			return 1;

		case 2:
			SendMessage(GetDlgItem(hWnd, IDC_EDIT2), WM_SETFONT, (WPARAM)CreateFont(50, 0, 0, 0, FW_REGULAR, FALSE, FALSE, FALSE, DEFAULT_CHARSET, OUT_DEFAULT_PRECIS, CLIP_DEFAULT_PRECIS, PROOF_QUALITY, DEFAULT_PITCH, "ＭＳ Ｐゴシック"), MAKELPARAM(TRUE, 0));
			SetDlgItemInt(hWnd, IDC_encoder_pitch, encoder_pitch_data, 1);//pitch location
			SetDlgItemInt(hWnd, IDC_encoder_yaw, encoder_yaw_data, 1);//yow location
			SetDlgItemInt(hWnd, IDC_encoder_zoom, encoder_zoom_data, 1);//zoom location

			//状態表示　初期値は3
			switch (operation_status) {
			case 0:
				SetWindowText(GetDlgItem(hWnd, IDC_EDIT2), _T("BREAK"));
				break;
			case 1:
				SetWindowText(GetDlgItem(hWnd, IDC_EDIT2), _T("PITCH"));
				break;
			case 2:
				SetWindowText(GetDlgItem(hWnd, IDC_EDIT2), _T("YAW"));
				break;
			case 3:
				SetWindowText(GetDlgItem(hWnd, IDC_EDIT2), _T("ZOOM IN"));
				break;
			case 4:
				SetWindowText(GetDlgItem(hWnd, IDC_EDIT2), _T("ZOOM OUT"));
				break;
			case 5:
				SetWindowText(GetDlgItem(hWnd, IDC_EDIT2), _T("now config"));
				break;
			}
			return 1;
		}
		break;
		// ×ボタンをクリックしたときの処理
	case WM_CLOSE:
		//ダイアログを破棄
		DestroyWindow(hWnd);
		//fclose(fp0);//ファイルを閉じる
		return 1;

		//終了(ウィンドウを閉じた後の)処理
	case WM_DESTROY:
		PostQuitMessage(0);
		//CSerialクラスの終了処理
		delete cserial;
		return 1;

	default:
		return FALSE;
	}
}

using namespace cv;
using namespace std;

int xb = 0, yb = 0;
int xbb = 0, ybb = 0;
int xq = 0, yq = 0;
int ct = 0;
int st = 0;

#ifdef _DEBUG
#pragma comment(lib, "opencv_world452d.lib")
#else
#pragma comment(lib, "opencv_world452.lib")
#endif

Point minPoint(vector<Point> contours) {
	double minx = contours.at(0).x;
	double miny = contours.at(0).y;
	for (int i = 1; i < contours.size(); i++) {
		if (minx > contours.at(i).x) {
			minx = contours.at(i).x;
		}
		if (miny > contours.at(i).y) {
			miny = contours.at(i).y;
		}
	}
	return Point(minx, miny);
}
//最大座標を求める
Point maxPoint(vector<Point> contours) {
	double maxx = contours.at(0).x;
	double maxy = contours.at(0).y;
	for (int i = 1; i < contours.size(); i++) {
		if (maxx < contours.at(i).x) {
			maxx = contours.at(i).x;
		}
		if (maxy < contours.at(i).y) {
			maxy = contours.at(i).y;
		}
	}
	return Point(maxx, maxy);
}

Mat mask1(Mat img) {
	Mat mask, mask2, bgf1;
	int White = 0;
	Mat kernel = getStructuringElement(MORPH_RECT, Size(21, 21));

	//inRange(img, Scalar(28, 64, 0), Scalar(77, 255, 255), mask);
	inRange(img, Scalar(24, 64, 0), Scalar(81, 255, 255), mask);
	morphologyEx(mask, mask2, MORPH_OPEN, kernel);
	for (int i = 0; i < 3; i++) {
		morphologyEx(mask2, mask2, MORPH_OPEN, kernel);
		medianBlur(mask2, mask2, 5);
	}
	threshold(mask2, bgf1, 120, 255, THRESH_BINARY);
	return bgf1;
}

Mat mask2(Mat img) {
	Mat mask3, mask4, bgf2;
	Mat kernel = getStructuringElement(MORPH_RECT, Size(21, 21));
	inRange(img, Scalar(133, 64, 0), Scalar(182, 255, 255), mask3);
	//inRange(img, Scalar(129, 64, 0), Scalar(186, 255, 255), mask3);
	morphologyEx(mask3, mask4, MORPH_OPEN, kernel);
	for (int i = 0; i < 3; i++) {
		morphologyEx(mask4, mask4, MORPH_OPEN, kernel);
		medianBlur(mask4, mask4, 5);
	}
	threshold(mask4, bgf2, 120, 255, THRESH_BINARY);
	return bgf2;
}

Mat Optical(Mat img1, Mat img2) {
	Mat flow(img1.size(), CV_32FC2);
	calcOpticalFlowFarneback(img1, img2, flow, 0.5, 3, 17, 3, 5, 1.1, 0);
	Mat flow_copy;
	//GaussianBlur(flow, flow_copy, cv::Size(3, 3), 0, 0);
	// visualization
	Mat flow_parts[2];
	split(flow, flow_parts);
	//split(flow_copy, flow_parts);

	//split(flow, flow_parts);
	Mat magnitude, angle, magn_norm;
	cartToPolar(flow_parts[0], flow_parts[1], magnitude, angle, true);
	normalize(magnitude, magn_norm, 0.0f, 1.0f, NORM_MINMAX);
	//imshow("an", magn_norm);

	angle *= ((1.f / 360.f) * (180.f / 255.f));
	//build hsv image
	Mat _hsv[3], hsv, hsv8, bgr;
	_hsv[0] = angle;
	_hsv[1] = Mat::ones(angle.size(), CV_32F);
	_hsv[2] = magn_norm;

	Mat h1, h2, h12;
	threshold(_hsv[0], h1, 60, 360, THRESH_BINARY);

	threshold(_hsv[0], h2, 120, 360, THRESH_BINARY);
	bitwise_or(h1, h2, h12);
	merge(_hsv, 3, hsv);
	hsv.convertTo(hsv8, CV_8U, 255.0);

	return hsv8;
}

vector<vector<Point>> contours(Mat img) {
	vector< vector<Point> > contours;
	vector< vector<Point> > contours_subset;
	vector<Vec4i> hierarchy;
	findContours(img, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE);
	for (auto contour = contours.begin(); contour != contours.end(); contour++) {
		for (int i = 0; i < contours.size(); i++) {
			double area1 = 0;
			area1 = contourArea(contours.at(i));
			if (area1 > 23 && area1 < 40) {
				contours_subset.push_back(contours.at(i));
			}
		}
	}
	return contours_subset;
}

Point center(Point max, Point min, Point MAX, Point MIN) {
	Point v;
	int k = 0;
	double s1 = 0, s2 = 0;
	int P1X = MIN.x;
	int P1Y = MIN.y;
	int P2Y = min.y;
	int P2X = min.x;
	int P3X = MAX.x;
	int P3Y = MAX.y;
	int P4Y = max.y;
	int P4X = max.x;

	s1 = ((P4X - P2X) * (P1Y - P2Y) - (P4Y - P2Y) * (P1X - P2X)) / 2;
	s2 = ((P4X - P2X) * (P2Y - P3Y) - (P4Y - P2Y) * (P2X - P3X)) / 2;

	v = Point(0, 0);
	v.x = P1X + ((double)P3X - (double)P1X) * s1 / (s1 + s2);
	v.y = P1Y + ((double)P3Y - (double)P1Y) * s1 / (s1 + s2);

	return v;
}

Mat templateMatch(Mat src, Mat tmp, Mat frame) {

	int sumx = 0, sumy = 0;
	const int __TARGET_NUM__ = 30;
	Mat output, dst;
	//dst = src.clone();
	dst = frame.clone();
	//テンプレートマッチング
	matchTemplate(src, tmp, output, TM_CCOEFF);
	//0~1の値に標準化
	normalize(output, output, 0, 1, NORM_MINMAX, -1, Mat());
	//2次元から1次元へ変換
	Mat one_row = output.reshape(1, 1);

	vector<float> one_row_vec;
	vector<float> one_row_index;

	//cv::Mat -> std::vector に変換
	one_row_vec.assign(one_row.begin<float>(), one_row.end<float>());
	vector<int> index(one_row_vec.size());

	//ソートインデックス配列用に整数列を作成する(0,1,2,3,4,5......)
	iota(index.begin(), index.end(), 0);

	//ソートをかける
	sort(index.begin(), index.end(), [&](int a, int b) {return one_row_vec[a] > one_row_vec[b]; });

	for (int i = 0; i < __TARGET_NUM__; i++) {
		//std::cout << index[i] << ":" << one_row_vec[index[i]] << std::endl;
		if (one_row_vec[index[i]] > 0.999) {
			ct++;
			// 1次元から2次元に変換 
			int x = index[i] % output.cols;
			int y = index[i] / output.cols;

			if (ct == 1) {
				Rect roi_rect = Rect(x, y, tmp.cols, tmp.rows);
				rectangle(dst, roi_rect, Scalar(0, 255, 255), 3);
				//printf("%lf\n", one_row_vec[index[i]]);
				xb = x;
				yb = y;
			}
			else if (abs(x - xb) < 20 && abs(y - yb) < 20) {
				xbb = xb;
				ybb = yb;
				Rect roi_rect = Rect(x+20, y+25, tmp.cols, tmp.rows);
				rectangle(dst, roi_rect, Scalar(0, 255, 255), 3);
				//printf("%lf\n", one_row_vec[index[i]]);
				xb = x;
				yb = y;
				st = 0;
			}
			else {
				xb = xbb;
				yb = ybb;
				st++;
			}
		}
	}
	if (st > 20) {
		//exit(1);
	}

	return dst;
}

Mat Bit_Wise(Mat img1, Mat img2) {
	Mat img1_gry, img2_gry, img_gry;
	cvtColor(img1, img1_gry, COLOR_BGR2GRAY);
	cvtColor(img2, img2_gry, COLOR_BGR2GRAY);
	
	absdiff(img1_gry, img2_gry, img_gry);
	

	return img_gry;
}

int MatArea(Mat canny) {
	vector<int> Area(1000);
	dilate(canny, canny, Mat(), Point(-1, -1), 3);
	
	vector<vector<Point> > contours;
	findContours(canny, contours, RETR_TREE, CHAIN_APPROX_SIMPLE);

	Mat drawing = Mat::zeros(canny.size(), CV_8UC3);
	RNG rng(12345);

	for (size_t i = 0; i < contours.size(); i++) {
		Scalar color = cv::Scalar(rng.uniform(0, 256), rng.uniform(0, 256), rng.uniform(0, 256));
		drawContours(drawing, contours, (int)i, color);
		Area.at(i) = contourArea(contours[i]);
	}

	sort(Area.begin(), Area.end(), greater<int>());

	return Area.at(0);
}
//画像処理関数
//int main(int argc, const char* argv[])
unsigned int __stdcall camera(PVOID pv)
{

	//VideoCapture capture("WIN_20211111_12_16_19_Pro_Trim.mp4");
	VideoCapture capture(0);
	VideoWriter writer;

	int width, height, fourcc;
	double fps, fps1;
	fourcc = cv::VideoWriter::fourcc('X', 'V', 'I', 'D');
	//fourcc = cv::VideoWriter::fourcc('m', 'p', '4', 'v');
	width = (int)capture.get(cv::CAP_PROP_FRAME_WIDTH);
	height = (int)capture.get(cv::CAP_PROP_FRAME_HEIGHT);
	//fps1 = capture.get(cv::CAP_PROP_FPS);
	fps = 5.0;
	int k = 0, c = 0, cc = 0;
	int sigma = 5, border = 9;
	int s = 0;
	int step = 0;
	int point = 0;
	vector<Point> v(95);
	int White = 0;
	int White_tmp = 0;
	int before_White = 0;
	int diff_Flag = 0;
	int origin_White = 0;
	int checkwhite = 0;
	int checkpoint = 0;
	vector<int> countx(5);
	vector<int> county(5);
	int e = 0, r = 0;
	Rect part(0, 0, 150, 100);
	const char* name1 = "Comfigure";
	const char* name2 = "Detection";
	const char* name3 = "Output";

	//writer.open("Video.mp4", fourcc, fps, cv::Size(width, height));
	writer.open("CloneVideo.avi", fourcc, fps, cv::Size(width, height), false);
	if (!capture.isOpened()) {
		//error in opening the video input
		cerr << "Unable to open file!" << endl;
		return 0;
	}

	for (;;) {
		startWindowThread();
		for (;;) {
			Mat frame,rame2,rame2_gry,difframe,difframe_canny;
			Mat useframe, useframe_gry, useframe_canny, Use;
			Mat imframe, noframe;

			for (;;) {
				waitKey(2);
				if (state == 2) {
					DestroyWindow(hWnd);
					break;
				}
				if (STATUS == 0) {
					for (;;) {
						waitKey(2);
						capture >> frame;
						waitKey(2);
						if (frame.empty()) {
							break;
						}
						moveWindow(name1, 1900, 0);
						useframe = frame(part);
						resize(frame, imframe, Size(),2,2);
						imshow(name1, imframe);

						cvtColor(useframe, useframe_gry, COLOR_BGR2GRAY);
						waitKey(1);
						capture >> rame2;
						rame2 = rame2(part);
						cvtColor(rame2, rame2_gry, COLOR_BGR2GRAY);
						absdiff(useframe_gry, rame2_gry, difframe);
						Canny(difframe, difframe_canny, 100, 15, 3, true);
						
						//Canny(useframe_gry, useframe_canny, 10, 15, 3, true);
						//blur(difframe_canny, difframe_canny, Size(5,5));
						Use = difframe_canny.clone();
						checkwhite = MatArea(difframe_canny);
						//imshow("shiro", Use);
						waitKey(2);
						if (checkwhite > 7000) {
							checkpoint++;
						}

						if (checkpoint > 3) {
							STATUS = 1;
							checkpoint = 0;
						}

						if (STATUS == 1 || state == 2) {
							waitKey(2);
							moveWindow(name1, 0, 0);
							resize(frame, noframe, Size(), 0.3, 0.3);
							imshow(name1, noframe);
							break;
						}
					}
				}
				if (STATUS == 1) {
					break;
				}
			}
			Mat frame1, prvs, prvs1, prvs11,prvs1blur;
			waitKey(2);
			capture >> frame1;
			waitKey(2);
			Rect selection(150, 50, 400, 350);
			Mat copy1, copy2;

			frame1 = frame1(selection);

			cvtColor(frame1, prvs1, COLOR_BGR2GRAY);
			copy1 = prvs1.clone();//差分用1
			medianBlur(prvs1, prvs1blur, 5);
			bilateralFilter(prvs1blur, prvs11, 5, sigma, border);
			bilateralFilter(prvs11, prvs, 5, sigma, border);

			Mat frame2, frame3, frame4,frame5;
			Point G = cv::Point(0, 0);

			//動体検出部
			for (;;) {
				Mat next, next1, next11,next1blur;
				Mat diffimg,diffblur;
				Mat use_frame2;
				Mat edge_img,edgeblur;
				Mat imframe3, noframe3;

				vector< vector<Point> > contours_subset1;
				vector< vector<Point> > contours_subset2;
				Point minP1 = Point(0, 0);
				Point maxP1 = Point(0, 0);
				Point minP2 = Point(0, 0);
				Point maxP2 = Point(0, 0);
				Point imminP1 = Point(0, 0);
				Point immaxP1 = Point(0, 0);
				Point imminP2 = Point(0, 0);
				Point immaxP2 = Point(0, 0);
				
				waitKey(1);
				capture >> frame2;
				waitKey(1);
				frame3 = frame2.clone();//描画用の画像

				if (frame2.empty()) {
					STATUS = 0;
					break;
				}
				else if (frame3.empty()) {
					STATUS = 0;
					break;
				}

				use_frame2 = frame2(selection);
				cvtColor(use_frame2, next1, COLOR_BGR2GRAY);
				copy2 = next1.clone();//差分用2
				
				absdiff(copy1, copy2, diffimg);//差分画像生成
				blur(diffimg, diffblur, Size(5, 5));
				Mat dcanny;
				Canny(diffblur, dcanny, 10, 15, 3, true);
				
				White = MatArea(dcanny);
				
				if (White < 18000) {//鉗子遠め
					sigma = 7;
					border = 5;
				}
				else {//鉗子近め
					sigma = 5;
					border = 9;
				}

				medianBlur(next1, next1blur, 5);
				bilateralFilter(next1blur, next11, 5, sigma, border);
				bilateralFilter(next11, next, 5, sigma, border);

				edge_img = next.clone();//エッジ用画像生成

				Mat hsv8 = Optical(prvs, next);
				Mat bgf1 = mask1(hsv8);
				Mat bgf2 = mask2(hsv8);
				Mat bgf1and, bgf2and;

				Canny(edge_img, edgeblur, 10, 15, 3, true);//エッジ強調
				bitwise_and(edgeblur, bgf1, bgf1and);
				bitwise_and(edgeblur, bgf2, bgf2and);
				
				contours_subset1 = contours(bgf1and);
				contours_subset2 = contours(bgf2and);
				for (int i = 0; i < contours_subset1.size(); i++) {
					minP1 = minPoint(contours_subset1.at(i));
					maxP1 = maxPoint(contours_subset1.at(i));

					minP1.x = minP1.x + 150.0;
					minP1.y = minP1.y + 50.0;

					maxP1.x = maxP1.x + 150.0;
					maxP1.y = maxP1.y + 50.0;
					imminP1 = minP1;
					immaxP1 = maxP1;
				}

				for (int i = 0; i < contours_subset2.size(); i++) {
					minP2 = minPoint(contours_subset2.at(i));
					maxP2 = maxPoint(contours_subset2.at(i));

					minP2.x = minP2.x + 150.0;
					minP2.y = minP2.y + 50.0;

					maxP2.x = maxP2.x + 150.0;
					maxP2.y = maxP2.y + 50.0;
					imminP2 = minP2;
					immaxP2 = maxP2;
				}
				putText(frame3, "DETECTING NOW", Point(200, 100), FONT_ITALIC, 1.2, Scalar(255, 0, 0), 2);

				if (minP1.x > 30 && minP2.x > 30 && maxP1.x < 430 && maxP2.x < 430) {

					if (minP1.y < minP2.y) {
						imminP1.y = minP1.y + 20.0;
						immaxP1.y = maxP1.y - 20.0;
					}
					else {
						imminP2.y = minP2.y - 20.0;
						immaxP2.y = maxP2.y + 20.0;
					}
					line(frame3, imminP1, immaxP1, Scalar(0, 255, 0), 4, 8);
					line(frame3, imminP2, immaxP2, Scalar(0, 0, 255), 4, 8);

					v.at(k) = center(immaxP1, imminP1, immaxP2, imminP2);
					if (v.at(k).x < 30 || v.at(k).y < 120 || v.at(k).x > 400 || v.at(k).y > 450)
						continue;

					circle(frame3, v.at(k), 10, Scalar(105, 155, 55), 3, 8);
					countx.at(k) = v.at(k).x;
					county.at(k) = v.at(k).y;

					if (k == 4) {
						waitKey(1);
						sort(countx.begin(), countx.end());
						sort(county.begin(), county.end());
						G.x = countx.at(2);
						G.y = county.at(2);
						circle(frame3, G, 15, Scalar(255, 0, 255), 3, 8);
						k = 0;
						e = 1;
					}
					k++;
				}
				
				waitKey(1);
				moveWindow(name2, 1900, 0);
				resize(frame3,imframe3, Size(),2,2);
				imshow(name2, imframe3);
				waitKey(1); 

				if (e == 1) {
					if (G.x > 45 && G.y > 65 && G.x < 540 && G.y < 340) {
						r = 1;
					}
					e = 0;
				}

				prvs = next;
				copy1 = copy2;

				if (r > 0) {
					countx = {0,0,0,0,0};
					county = {0,0,0,0,0};
					r = 0;
					k = 0;
					waitKey(1);
					frame1.release();
					waitKey(1);
					frame2.release();
					waitKey(1);
					step = 1;
					waitKey(1);
					capture >> frame4;
					waitKey(1);
					moveWindow(name2, 0, 300);
					resize(frame3, noframe3, Size(), 0.3, 0.3);
					imshow(name2, noframe3);
					break;
				}
			}

			cserial->m_senddata[0] = (unsigned char)START;
			cserial->SerialPortBufferClear();
			cserial->SendSerialData(1);
			send_count = 0;
			
			//切り取り領域取得と処理
			Rect roi;
			Rect roi_origin;
			int point_x = 0, point_y = 0;
			int x_weidth = 320, y_height = 300;
			
			roi = Rect(G.x - 25, G.y - 30, 195, 175);//Matching
			roi_origin = Rect(190, 70, x_weidth, y_height);//Detection
			
			point_x = G.x - 45, point_y = G.y - 50;
			Mat tmp = frame4(roi);
			Mat tmp_clone = frame4(roi_origin);
			Mat edge_roi, tmp_roi;
			Mat gry_clone,gry_clone1, gry_clone2;

			capture >> frame5;
			Mat tmp2 = frame5(roi);
			Mat tmp2_gry, edge_roi2,diffedge;

			cvtColor(tmp_clone, gry_clone, COLOR_BGR2GRAY);
			//Canny(diffedge, edge_roi2, 100, 15, 3, true);
			diffedge = Bit_Wise(tmp, tmp2);
			Canny(diffedge, edge_roi2, 50, 100, 3, true);
			
			Mat diffedge_copy = edge_roi2.clone();
			Mat edge_roi_erode = edge_roi.clone();
			imshow("a", diffedge_copy);
			double shiro_edge = countNonZero(edge_roi2);
			double edge_per = shiro_edge * 100 / (double(roi.width) * double(roi.height));
			if (edge_per<4 || point_x < 0 || point_y < 0) {
				waitKey(1);
				step = 0;
				STATUS = 1;
			}
			int White_tmp = MatArea(edge_roi2);

			medianBlur(gry_clone, gry_clone, 5);
			bilateralFilter(gry_clone, gry_clone1, 5, sigma, border);
			bilateralFilter(gry_clone1, gry_clone2, 5, sigma, border);

			int up_flag = 0, down_flag = 0, left_flag = 0, right_flag = 0, stop_flag1 = 0;
			int in_flag = 0, out_flag = 0, stop_flag2 = 0;
			
			//トラッキング
			for (;;) {
				Mat img1, img2, src, dst, imdst, nodst;
				Mat img_gry, edge, edge_canny;
				Mat src4, src4_gry, src4_gry1, src4_gry2, src4_blur;
				Mat src_clone, srcedge;
				capture >> img1;
				capture >> img2;
				src = img2.clone();
				src4 = img2(roi_origin).clone();

				vector< vector<Point> > contours_subset11;
				vector< vector<Point> > contours_subset22;
				Point minP11 = Point(0, 0);
				Point maxP11 = Point(0, 0);
				Point minP22 = Point(0, 0);
				Point maxP22 = Point(0, 0);

				img_gry = Bit_Wise(img1, img2);
				edge = img_gry.clone();
				Canny(edge, edge_canny, 50, 100, 3, true);
				Mat edge_dilate = edge_canny.clone();
				imshow("an", diffedge_copy);
				imshow("d", edge_canny);
				dst = templateMatch(edge_canny,diffedge_copy,src);
				int White = MatArea(edge_dilate(roi));
				cc++;
					
				if (cc == 1) {
					origin_White = White;
				}
					
				if (White < 1000) {
					diff_Flag = 1;
				}
				else {
					diff_Flag = 0;
				}
				rectangle(dst, roi_origin, Scalar(255, 55, 255), 3);
				cvtColor(src4, src4_gry, COLOR_BGR2GRAY);
				medianBlur(src4_gry, src4_blur, 5);
				bilateralFilter(src4_blur, src4_gry1, 5, sigma, border);
				bilateralFilter(src4_gry1, src4_gry2, 5, sigma, border);

				src_clone = src4_gry.clone();
				Canny(src_clone, srcedge, 10, 15, 3, true);//エッジ強調

				Mat hsv88 = Optical(gry_clone2, src4_gry2);
				Mat bgf11 = mask1(hsv88);
				Mat bgf22 = mask2(hsv88);

				bitwise_and(srcedge, bgf11, bgf11);
				bitwise_and(srcedge, bgf22, bgf22);

				contours_subset11 = contours(bgf11);
				contours_subset22 = contours(bgf22);
				for (int i = 0; i < contours_subset11.size(); i++) {
					minP11 = minPoint(contours_subset11.at(i));
					maxP11 = maxPoint(contours_subset11.at(i));

					minP11.x = minP11.x + 200.0;
					minP11.y = minP11.y + 70.0;

					maxP11.x = maxP11.x + 200.0;
					maxP11.y = maxP11.y + 70.0;
				}

				for (int i = 0; i < contours_subset22.size(); i++) {
					minP22 = minPoint(contours_subset22.at(i));
					maxP22 = maxPoint(contours_subset22.at(i));

					minP22.x = minP22.x + 200.0;
					minP22.y = minP22.y + 70.0;

					maxP22.x = maxP22.x + 200.0;
					maxP22.y = maxP22.y + 70.0;
				}

				if (minP11.x > 30 && minP22.x > 30 && maxP11.x < 430 && maxP22.x < 430) {
					cv::line(dst, minP11, maxP11, cv::Scalar(0, 255, 0), 4, 8);
					cv::line(dst, minP22, maxP22, cv::Scalar(0, 0, 255), 4, 8);
					point++;
				}

				if (point > 7) {
					ct = 0;
					cc = 0;
					step = 0;
					point = 0;
					send_count = 9;
					STATUS = 0;
					waitKey(2);
					moveWindow(name3, 0, 500);
					resize(dst, nodst, Size(), 0.2, 0.2);
					imshow(name3, nodst);
					break;
				}

				if (xb < 180 && xb > 100) {
					point = 0;
					putText(dst, "Left Over", Point(300, 400), FONT_ITALIC, 1.2, Scalar(255, 200, 100), 2);
					left_flag = 1;
					if (encoder_yaw_data > 680 && encoder_yaw_data < 750) {
						xb = xb + 2;
					}
				}
				else if (xb > 300 && xb < 380) {
					putText(dst, "Right Over", Point(300, 400), FONT_ITALIC, 1.2, Scalar(255, 200, 100), 2);
					right_flag = 1;
					if (encoder_yaw_data < 640 && encoder_yaw_data > 570) {
						xb = xb - 2;
					}
				}
				else if (yb < 60 && yb >10) {
					point = 0;
					putText(dst, "Up Over", Point(300, 400), FONT_ITALIC, 1.2, Scalar(255, 200, 100), 2);
					up_flag = 1;
					if (encoder_pitch_data > 470 && encoder_pitch_data < 480) {
						yb = yb + 2;
					}
				}
				else if (yb > 180 && yb < 230) {
					point = 0;
					putText(dst, "Down Over", Point(300, 400), FONT_ITALIC, 1.2, Scalar(255, 200, 100), 2);
					down_flag = 1;
					if (encoder_pitch_data < 430 && encoder_pitch_data > 420) {
						yb = yb - 2;
					}
				}
				else {
					putText(dst, "Stop", Point(300, 400), FONT_ITALIC, 1.2, Scalar(255, 200, 100), 2);
					stop_flag1 = 1;
				}

				if (diff_Flag == 0 && (double)origin_White / (double)White < 0.8) {
					point = 0;
					putText(dst, "near by", Point(300, 100), FONT_ITALIC, 1.2, Scalar(55, 200, 100), 2);
					out_flag = 1;
				}
				else if (diff_Flag == 0 && (double)origin_White / (double)White > 2.6) {
					point = 0;
					putText(dst, "far away", Point(300, 100), FONT_ITALIC, 1.2, Scalar(55, 200, 100), 2);
					in_flag = 1;
				}
				else {
					putText(dst, "Stop", Point(300, 100), FONT_ITALIC, 1.2, Scalar(55, 200, 100), 2);
					stop_flag2 = 1;
				}

				if (left_flag == 1) {
					operation_status = 2;
					if (in_flag == 1) {
						send_count = 10;
					}
					else if (out_flag == 1) {
						send_count = 11;
					}
					else {
						send_count = 3;
					}
					left_flag = 0;
				}
				else if (right_flag == 1) {
					operation_status = 2;
					if (in_flag == 1) {
						send_count = 12;
					}
					else if (out_flag == 1) {
						send_count = 13;
					}
					else {
						send_count = 4;
					}
					right_flag = 0;
				}
				else if (up_flag == 1) {
					operation_status = 1;
					if (in_flag == 1) {
						send_count = 14;
					}
					else if (out_flag == 1) {
						send_count = 15;
					}
					else {
						send_count = 5;
					}
					up_flag = 0;
				}
				else if (down_flag == 1) {
					operation_status = 1;
					if (in_flag == 1) {
						send_count = 16;
					}
					else if (out_flag == 1) {
						send_count = 17;
					}
					else {
						send_count = 6;
					}
					down_flag = 0;
				}
				else if (stop_flag1 == 1) {
					if (in_flag == 1) {
						send_count = 7;
					}
					else if (out_flag == 1) {
						send_count = 8;
					}
					else {
						send_count = 9;
					}
					stop_flag1 = 0;
				}
				in_flag = 0;
				out_flag = 0;
				circle(dst, G, 10, Scalar(5, 155, 55), 3, 8);
				Rect roiroi = Rect(xb, yb, roi.width, roi.height);
				diffedge_copy = edge_canny(roiroi);
				waitKey(1);
				moveWindow(name3, 1900, 0);
				resize(dst, imdst,Size(),2,2);
				imshow(name3, imdst);
				waitKey(1);
			}
		}
	}
	return 0;
}

int WINAPI WinMain(HINSTANCE hInst, HINSTANCE hPrevInst, LPSTR szStr, int iCmdShow)
{
	//モーダルダイアログボックスを作成
	DialogBox(
		hInst,
		MAKEINTRESOURCE(IDD_DIALOG1),
		NULL,
		(DLGPROC)DlgWndProc);

	while (GetMessage(&msg, NULL, 0, 0))
	{
		TranslateMessage(&msg); // キーボードメッセージを変換する
		DispatchMessage(&msg);  // 1つのウィンドウプロシージャにメッセージを送る
	}
	return msg.wParam;
	//return 0;

}
